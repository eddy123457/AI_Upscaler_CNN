{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3IcXaPEQFOJYOgHbvsK+D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eddy123457/AI_Upscaler_CNN/blob/main/AI_upscalerCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#train model here\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import ssl\n",
        "# cancels out the SSL requirement\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "#data set is from kereas includes uptp 60,000 images\n",
        "(x_train_lowres, _), (x_test_lowres, _) = cifar10.load_data()\n",
        "#normalize pixels [0,1] with low res\n",
        "x_train_lowres = x_train_lowres.astype('float32') / 255.0\n",
        "x_test_lowres = x_test_lowres.astype('float32') / 255.0\n",
        "#resize the low res images\n",
        "x_train_highres = tf.image.resize(x_train_lowres, (64, 64)).numpy()\n",
        "x_test_highres = tf.image.resize(x_test_lowres, (64, 64)).numpy()\n",
        "\n",
        "def upscalingV2():\n",
        "    #we use seq model because it allows more layers to be added\n",
        "    model = models.Sequential()\n",
        "    #first layer 64 filters and a filter has a (3,3) kernal\n",
        "    #Rectified Linear unit is used\n",
        "    #padding is the same so we always have the same spatial dimensions\n",
        "    #input_shape allows for anysized imaged to be used on model\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(None, None, 3)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    #same as before but we add 128 filteres\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    #heres where we do the actual upscaling by factor of two\n",
        "    #takes way to long to increase this\n",
        "    model.add(layers.UpSampling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    #we use this since we normalized first\n",
        "    model.add(layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same'))\n",
        "\n",
        "    return model\n",
        "\n",
        "upscalingmodelV2 = upscalingV2()\n",
        "#adam optimizer with learning rate of .001 ans mse is used to calulate loss on training epoch\n",
        "upscalingmodelV2.compile(optimizer=Adam(learning_rate=0.001), loss=tf.keras.losses.MeanSquaredError())\n",
        "\n",
        "upscalingmodelV2.summary()\n",
        "\n",
        "# Save the model during training just in case my computer crashes again\n",
        "checkpoint = ModelCheckpoint('eds_upscaler_model.h5', save_best_only=True)\n",
        "\n",
        "# Train the model 10 epochs and a batch size of 32 images consisting of low and high res imgs\n",
        "history = upscalingmodelV2.fit(x_train_lowres, x_train_highres, epochs=10, batch_size=32,\n",
        "                              validation_data=(x_test_lowres, x_test_highres),\n",
        "                              callbacks=[checkpoint])\n",
        "\n",
        "# Display model statistics\n",
        "print(\"Training History:\")\n",
        "print(history.history)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss = upscalingmodelV2.evaluate(x_test_lowres, x_test_highres)\n",
        "print(f\"\\nTest Loss: {test_loss}\")\n",
        "\n",
        "# Save the final model\n",
        "upscalingmodelV2.save('eds_upscaler_modelV2.h5')\n"
      ],
      "metadata": {
        "id": "_jf4pwjdQ9_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmDTIy93Qg2U"
      },
      "outputs": [],
      "source": [
        "\n",
        "#import model here\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "imagepath = \"img\"\n",
        "image = cv2.imread(imagepath)\n",
        "\n",
        "# Resize the Image to what we want\n",
        "size = (1920, 1080)\n",
        "resizedImage = cv2.resize(image, size)\n",
        "\n",
        "# make sure its a colored image\n",
        "if len(resizedImage.shape) == 2:\n",
        "    resizedImage = cv2.cvtColor(resizedImage, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "# normalize the img\n",
        "normalizedImage = resizedImage.astype('float32') / 255.0\n",
        "\n",
        "# show side by side original and normalized image\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Normalized Image\")\n",
        "plt.imshow(normalizedImage)\n",
        "plt.show()\n",
        "\n",
        "preprocessedImage=normalizedImage\n",
        "preprocessedImage = cv2.cvtColor(preprocessedImage, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Load the my pre trained upscaling model\n",
        "upscalingModelPath = \"//eds_upscaler_modelV2.h5\"\n",
        "upscalingModel = load_model(upscalingModelPath)\n",
        "\n",
        "# Expand dimensions to match the model's expected input shape\n",
        "inputImage = tf.expand_dims(preprocessedImage, axis=0)\n",
        "\n",
        "# Use the model to generate the high-resolution image\n",
        "generated_image = upscalingModel.predict(inputImage)\n",
        "\n",
        "# Display the Original and Generated Images\n",
        "# Expand dimensions to match the model's expected input shape\n",
        "inputImage = tf.expand_dims(preprocessedImage, axis=0)\n",
        "\n",
        "# create a new picture\n",
        "generatedimage = upscalingModel.predict(inputImage)\n",
        "\n",
        "#show result\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Preprocessed Image\")\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Generated Image\")\n",
        "plt.imshow(generatedimage[0])  # Access the first  element in the batch\n",
        "plt.show()"
      ]
    }
  ]
}
